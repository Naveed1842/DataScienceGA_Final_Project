{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn import cross_validation\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"yellow_tripdata_2015-01-1p.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['log_total_amount'] = df['total_amount'].apply(lambda x: np.log(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['total_amount'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['log_total_amount'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dt(x):\n",
    "    return datetime.strptime(x, '%m/%d/%Y %H:%M')\n",
    "\n",
    "df['tpep_pickup_datetime'] = df.apply(lambda x: get_dt(x[1]), axis=1)\n",
    "df['tpep_dropoff_datetime'] = df.apply(lambda x: get_dt(x[2]), axis=1)\n",
    "\n",
    "df['tpep_pickup_dayofweek'] = df['tpep_pickup_datetime'].dt.dayofweek\n",
    "#df['tpep_dropoff_dayofweek'] = df['tpep_dropoff_datetime'].dt.dayofweek\n",
    "\n",
    "#df['tpep_pickup_time'] = df['tpep_pickup_time'].astype(\"int\")\n",
    "df['tpep_pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "#df['tpep_pickup_minuteofday'] = df['tpep_pickup_time'].apply(lambda x: x.hour) * 60 + df['tpep_pickup_time'].apply(lambda x: x.minute)\n",
    "#df['tpep_dropoff_time'] = df['tpep_dropoff_datetime'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(['store_and_fwd_flag',\n",
    "              'pickup_longitude',\n",
    "              'pickup_latitude',\n",
    "              'tpep_pickup_datetime', \n",
    "              'tpep_dropoff_datetime',\n",
    "              'dropoff_longitude',\n",
    "              'dropoff_latitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df['RateCodeID'] == 1]\n",
    "df = df[df['borough'] == 'Manhattan']\n",
    "df = df[df['passenger_count']!= 0]\n",
    "df = df[df['trip_distance']!= 0]\n",
    "df = df[df['fare_amount'] > 0]\n",
    "df = df[df['borough']!= '0']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.pairplot(df, vars=['total_amount', 'tpep_pickup_dayofweek', 'tpep_pickup_hour', 'tip_amount'], hue=\"neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "df.plot(kind ='scatter', x='tpep_pickup_hour', y='total_amount', alpha=0.1)\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Total Amount')\n",
    "plt.axis([0, 24, 0, 100])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n",
    "df.plot(kind ='scatter', x='tpep_pickup_dayofweek', y='total_amount', alpha=0.1)\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Total Amount')\n",
    "plt.axis([-1, 7, 0, 100])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='tpep_pickup_dayofweek', y='total_amount', data=df)\n",
    "plt.ylim(0, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='tpep_pickup_hour', y='total_amount', data=df)\n",
    "plt.ylim(0, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.join(pd.get_dummies(df['tpep_pickup_hour'], prefix='hour'))\n",
    "df = df.join(pd.get_dummies(df['tpep_pickup_dayofweek'], prefix='week'))\n",
    "df = df.join(pd.get_dummies(df['neighborhood'], prefix='n'))\n",
    "#df = pd.get_dummies(df).astype(np.int8)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(['VendorID',\n",
    "              'neighborhood',\n",
    "              'RateCodeID',\n",
    "              'tpep_pickup_dayofweek',\n",
    "              'tpep_pickup_hour',\n",
    "              'borough'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "cmap = sns.diverging_palette(300, 10, as_cmap=True)\n",
    "\n",
    "correlations = df.corr()\n",
    "print correlations\n",
    "print sns.heatmap(correlations, cmap=cmap, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "y = df['total_amount']\n",
    "log_y = np.log10(y+1)\n",
    "lm = smf.ols(formula=' log_y ~ hour_0 + hour_1 + hour_2 + hour_3 + hour_4 + hour_5 + hour_6 + hour_7 + hour_8 + hour_9 + hour_10 + hour_11 + hour_12 + hour_13 + hour_14 + hour_15 + hour_16 + hour_18 + hour_19 + hour_20 + hour_21 + hour_22 + hour_23 + week_0 + week_1 + week_2 + week_3 + week_4 + week_5 + week_6' , data=df).fit()\n",
    "#print the full summary\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set target variable name\n",
    "target = 'total_amount'\n",
    "\n",
    "# Set X and y\n",
    "X = df.drop([target], axis=1)\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "# Create separate training and test sets with 60/40 train/test split\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "# check size of training set\n",
    "print X_train.shape, y_train.shape\n",
    "\n",
    "# check size of test set\n",
    "print X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_selection, linear_model\n",
    "\n",
    "def get_linear_model_metrics(X, y, algo):\n",
    "    # get the pvalue of X given y. Ignore f-stat for now.\n",
    "    pvals = feature_selection.f_regression(X, y)[1]\n",
    "    # start with an empty linear regression object\n",
    "    # .fit() runs the linear regression function on X and y\n",
    "    algo.fit(X,y)\n",
    "    residuals = (y-algo.predict(X)).values\n",
    "\n",
    "    # print the necessary values\n",
    "    print 'P Values:', pvals\n",
    "    print 'Coefficients:', algo.coef_\n",
    "    print 'y-intercept:', algo.intercept_\n",
    "    print 'R-Squared:', algo.score(X,y)\n",
    "    #plot hist of errors\n",
    "    plt.figure()\n",
    "    plt.hist(residuals, bins=np.ceil(np.sqrt(len(y))))\n",
    "    # keep the model\n",
    "    return algo\n",
    "\n",
    "lm = linear_model.LinearRegression(fit_intercept=False)\n",
    "lm = get_linear_model_metrics(X_train, y_train, lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = cross_validation.KFold(len(X_train), n_folds=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "mse_values = []\n",
    "scores = []\n",
    "n= 0\n",
    "print \"~~~~ CROSS VALIDATION each fold ~~~~\"\n",
    "for train_index, test_index in kf:\n",
    "    lm = linear_model.LinearRegression().fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "    mse_values.append(metrics.mean_squared_error(y_train.iloc[test_index], lm.predict(X_train.iloc[test_index])))\n",
    "    scores.append(lm.score(X_train, y_train))\n",
    "    n+=1\n",
    "    print 'Model', n\n",
    "    print 'MSE:', mse_values[n-1]\n",
    "    print 'R2:', scores[n-1]\n",
    "\n",
    "\n",
    "print \"~~~~ SUMMARY OF CROSS VALIDATION ~~~~\"\n",
    "print 'Mean of MSE for all folds:', np.mean(mse_values)\n",
    "print 'Mean of R2 for all folds:', np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "print \"~~~~ Single Model ~~~~\"\n",
    "print 'MSE of single model:', metrics.mean_squared_error(y_train, lm.predict(X_train))\n",
    "print 'R2: ', lm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit linear regression using no regularization (OLS)\n",
    "lm = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "print \"~~~ No regularization (OLS) ~~~\"\n",
    "print 'OLS MSE: ', metrics.mean_squared_error(y_train, lm.predict(X_train))\n",
    "print 'OLS R2:', lm.score(X_train, y_train)\n",
    "\n",
    "# fit linear regression using L1 regularization (Lasso)\n",
    "lm = linear_model.Lasso().fit(X_train, y_train)\n",
    "print \"~~~ L1 regularization (Lasso) ~~~\"\n",
    "print 'Lasso MSE: ', metrics.mean_squared_error(y_train, lm.predict(X_train))\n",
    "print 'Lasso R2:', lm.score(X_train, y_train)\n",
    "\n",
    "# fit linear regression using L2 regularization (Ridge)\n",
    "lm = linear_model.Ridge().fit(X_train, y_train)\n",
    "print \"~~~ L2 regularization (Ridge) ~~~\"\n",
    "print 'Ridge MSE: ', metrics.mean_squared_error(y_train, lm.predict(X_train))\n",
    "print 'Ridge R2:', lm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-10, 10, 21)\n",
    "for a in alphas:\n",
    "    print 'Alpha:', a\n",
    "    lm = linear_model.Ridge(alpha=a)\n",
    "    lm.fit(X_train, y_train)\n",
    "    print metrics.mean_squared_error(y_train, lm.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import grid search\n",
    "from sklearn import grid_search\n",
    "\n",
    "# pick range of values to search with\n",
    "alphas = np.logspace(-10, 10, 21)\n",
    "\n",
    "# use grid search CV to find best value\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.Ridge(),\n",
    "    param_grid={'alpha': alphas},\n",
    "    scoring='mean_squared_error')\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_to_approach, start, steps, optimized = 6.2, 0., [-1, 1], False\n",
    "while not optimized:\n",
    "    current_distance = num_to_approach - start\n",
    "    got_better = False\n",
    "    next_steps = [start + i for i in steps]\n",
    "    for n in next_steps:\n",
    "        distance = np.abs(num_to_approach - n)\n",
    "        if distance < current_distance:\n",
    "            got_better = True\n",
    "            print distance, 'is better than', current_distance\n",
    "            current_distance = distance\n",
    "            start = n\n",
    "    if got_better:\n",
    "        print 'found better solution! using', current_distance\n",
    "        a += 1\n",
    "    else:\n",
    "        optimized = True\n",
    "        print start, 'is closest to', num_to_approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_to_approach, start, steps, optimized = 6.2, 0., [-1, 1], False\n",
    "n_iter = 0\n",
    "while not optimized:\n",
    "    if n_iter > 3:\n",
    "        print 'stopping iterations'\n",
    "        break\n",
    "    n_iter += 1\n",
    "    current_distance = num_to_approach - start\n",
    "    got_better = False\n",
    "    next_steps = [start + i for i in steps]\n",
    "    for n in next_steps:\n",
    "        distance = np.abs(num_to_approach - n)\n",
    "        if distance < current_distance:\n",
    "            got_better = True\n",
    "            print distance, 'is better than', current_distance\n",
    "            current_distance = distance\n",
    "            start = n\n",
    "    if got_better:\n",
    "        print 'found better solution! using', current_distance\n",
    "        a += 1\n",
    "    else:\n",
    "        optimized = True\n",
    "        print start, 'is closest to', num_to_approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = linear_model.SGDRegressor()\n",
    "lm.fit(X_train, y_train)\n",
    "print \"Gradient Descent MSE:\", metrics.mean_squared_error(y_train, lm.predict(X_train))\n",
    "print \"Gradient Descent R2:\", lm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = linear_model.SGDRegressor()\n",
    "lm.fit(X_test, y_test)\n",
    "print \"Gradient Descent MSE:\", metrics.mean_squared_error(y_test, lm.predict(X_test))\n",
    "print \"Gradient Descent R2:\", lm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
